
# 3. Exploratory Data Analysis (EDA)

To proceed to the Exploratory Data Analysis (EDA), we use the **quanteda package**.

## Cloud of Words

To start the EDA, we proceed to visually assess which words are expected to be found the most regularly in the corpus. Thus, the CoW plot is a visual representation of term frequencies in which the size and position of terms are proportional to their frequencies. Nevertheless, this visualization is more graphic than informative since the only information we can extract from is that the terms with the largest font sizes are the most frequent in the corpus. Indeed, from the below plot, we see that *woman* is the most used term in the corpus, followed by *female*, *datum*, *male*, *find*, *time*, *gender* and *study*. 

To generate the CoW plot, we use the DTM that was obtained after cleaning and lemmatizing but without considering the stemming, see *Document-Term Matrix* in Section 2 **Data Structuring and Cleaning**.  

```{r cloud of words, echo=F, message=FALSE, warning=FALSE}

# Generate Cloud of Words plot
textplot_wordcloud(data.dfm)

```

## Global Frequency

To assess more accurately the frequency of the terms in the corpus, we compute the global frequencies. The following graphical representation displays the ten most frequent terms in the corpus. As inferred previously from the CoW, we see that *woman* is the most frequent term overall followed by *female*, *datum*, *male*, *find*, *time*, *gender* and *study*. 

Global frequencies indicate that *woman* is by far the most frequent term and that the frequency differences between the following nine terms are much less extreme. 

In addition, we see that the term *data* was lemmatized into *datum*. 

```{r TF-IDF plot, echo=F, message=F, warning=F}

# Generates counts and document frequencies summaries of the feature of the document-feature matrix "data.dfm"
data.freq <- textstat_frequency(data.dfm) 

#Plot the results 
tf_plot <- data.freq  %>% 
              top_n(10, frequency) %>%                    # selects the top 10 rows by frequency values
              ggplot(aes(x = reorder(feature, frequency), # orders terms by frequency values
                         y = frequency)) + 
              geom_bar(stat = "identity", fill = "dodgerblue3", alpha = 0.5) + # generates a barplot
              coord_flip() +                              # flips the coordinates
              labs(title = "Top 10 global frequencies",
                   subtitle = "",
                   x = "Term",
                   y = "Freqency",
                   caption = "source: Invisible Women.pdf")

tf_plot

```

### Term-Frequency (TF)

To deep dive into these frequencies, we then display a Term-Frequency (TF) table providing information on term frequencies, their rank and document frequencies. Indeed, the *feature* lists the lemmatized tokens, the *frequency* provides the number of times the term is found in the corpus, the *rank* sorts the terms by decreasing frequencies, the *docfreq* indicates the number of documents in which the token is found. 

The table below shows that *woman* appears 1594 times in the corpus which is four times more than the second most frequent term *female*. Moreover, all the terms have a high document-frequency. 

```{r term frequency, echo = FALSE, message = FALSE}

kbl(head(data.freq[,1:4], 
         10), 
    align = c('c', 'c', 'c', 'c', 'c'), #originally the data.freq has a column named group but as it is not relevant for us we select only the 3 first columns
    caption = "Term frequencies") %>% 
  kable_styling(bootstrap_options = c("striped", "hover"), 
                full_width = NULL)  

```

## Term-Frequency versus Document-Frequency 

The below graph gives an overall graphical view of the previous table indicating:
1) the term-frequency 
2) document-frequency

As observed previously, we see that *woman* is the most frequent term in the corpus and that it is the most frequent term over all chapters of the book. On the contrary, the terms *trial* and *tax* are less frequent overall and also less frequent in documents. 
 
For all the reasons mentioned until here, we decide to remove the term *woman* because we believe it can hide some important and interesting insights. For the rest of our analysis, it will be indicated if *woman* is integrated to our analysis again. 

```{r TF vs DF, echo=F, message=F, warning=F}

data.freq %>% 
 ggplot(aes(x = log(docfreq), 
            y = log(frequency))) +
 geom_text(aes(label = feature), 
           position = position_jitter(), 
           size = 3) + 
 labs(title = "TF versus DF (log-log)",
      subtitle = "",
      x = "Document log-frequency",
      y = "Term log-frequency",
      caption = "source: Invisible Women.pdf") +
  theme_minimal()

```

```{r second cleaning, echo = FALSE, message = FALSE}

# second cleaning without "woman"
data.tk3 <- data.tk2 %>% tokens_remove("woman")

# Creates a second document-feature matrix
data.dfm2 <- dfm(data.tk3) 

# generate second second doc frequency
data.freq2 <- textstat_frequency(data.dfm2)  

# Generate a second weighted document-feature matrix by tf-idf
data.tfidf <- dfm_tfidf(data.dfm2)

```

## Term-Frequency by Document 


The plot below shows kind of the same information than the frequency plot but with a little twist. Here, we show the top 10 more frequent words associated with their chapter. It would have been interesting to have the top frequencies of each documents but there would have been an information overload as there are 16 chapters, so we decided not to display it.

Chapter 10, namely **The Drugs Don't Work**, is associated with *sex*, *drug* and *study*. In the previous plot (TF versus DF), we saw that *sex* and *study* are not document-specific but that *drug* is more document-specific. Therefore, we can assume that *drug* is more specific to chapter 10 then the two other terms. Nevertheless, we do not want to jump to conclusion right now and the document-specificity of terms will be explored deeper later. 

Chapter 13, *From Purse to Wallet* seems to only be associated to *tax* and as well as *drug*, *tax* is more document-specific. 

Chapter 14, *Women's Rights are Human Rights* is only associated to *female*. 

Chapter 3, *The Long Friday* is related to *pay*, *leave* and *time* 

Lastly chapter 4, *Myth of Meritocracy* is equally associated to *female* and *male*. 

Even though some of those words are informative, others are much less insightful. Indeed, it is not enlightening to have *female* associated to one document as the whole book is about feminism.  

```{r term-frequency by document plot, echo=F, message=F, warning=F}

nowoman.10 <- data.dfm2 %>% 
               tidy() %>%  
               #group_by(term) %>% 
               # creates a tibble 
               top_n(10, count) %>%       # selects the top 10 rows by count   
               #ungroup() %>% 
               ggplot(aes(x = reorder(term, count), 
                          y = count)) +   
               geom_col(fill = "dodgerblue3", alpha = 0.5) + 
               coord_flip() + 
               labs(title = "Top 10 frequencies along with documents",
                    subtitle = "",
                    x = "Term",
                    y = "Freqency",
                    caption = "source: Invisible Women.pdf") +
               facet_wrap(~ document, 
                          ncol = 2) +
               theme_minimal() 

nowoman.10

```

## Zipf's Law

The Zipf's Law shows the distribution of words used in a corpus compared to his rank in the frequency table. It says that the frequency of a token is inversely proportional to its rank. The below plot is on a log-log scale, the frequency versus rank gives a negative linear relation as the original distribution is a negative exponential function. 

This plot shows that *female*, *datum*, *male*, *find* and *time* are the most frequent terms of the corpus probably indicating that they are not chapter-specific but are frequent in all chapters. Indeed, although Zipf's Law do not state about the specificity, there is a very low probability that those words are specific to a chapter that is sufficiently lengthy to make it as frequent. Therefore, according to the Zipf's Law, these terms are very frequent in the overall corpus and consequently could hide some meaningful information as they are not considered stop words. The Zipf's law now leads us to move to look at weighted frequencies. 

```{r Zipf law plot, echo = FALSE, message = FALSE}

# Illustration of the Zipf's law 
ggplot(data.freq2, 
       aes(x = log(rank), 
           y = log(frequency))) + 
   geom_point(color = "dodgerblue3", 
              alpha = 0.5) +
   geom_label(data = data.freq2[c(1:5,6627:6631)], 
              aes(label = feature)) +
   labs(title = "The Zipf's law on a log-log scale",
        subtitle = "",
        caption = "source: Invisible Women.pdf") +
   theme_minimal()


```

## Term-Frequency and Inverse-Document Matrix (TF-IDF)

The TF-IDF matrix is a weighted document-feature matrix displaying term frequency–inverse document frequency. In other words, it is used to re-balance a term frequency with respect to its document-specificity.

The below output shows, for the document-feature matrix of 16 documents and 5'741 features, the weighted frequency for each token by document. The sparsity has slightly increased in comparison to the DTM matrix as "women", a term occurring in all the document, has been removed.

```{r term frequency and inverse document matrix, echo=FALSE, message=FALSE}
# Weighted document-feature matrix by tf-idf
data.tfidf2 <- dfm_tfidf(data.dfm2)
data.tfidf2
```

The following plot shows the twenty largest TF-IDF and their respective terms. Note that it is equal to the result of computing for each term displayed the maximum TF-IDF over all chapters of the book. The output shows that *tax* has the largest TF-IDF in at least one chapter of the book and that *trial*, *drug* and *dummy* appear also quite often in the corpus and in few documents.

```{r max tf-idf, echo=F, message=F, warning=F,fig.width=8}

data.tfidf2 %>% 
    tidy() %>%
    group_by(term) %>%
    summarize(count = max(count)) %>% 
    arrange(desc(count)) %>%
    top_n(20, count) %>%
    ggplot(aes(x = reorder(term, count), 
               y = count)) + 
    geom_bar(stat = "identity", 
             fill = "dodgerblue3", 
             alpha = 0.5) + 
    coord_flip() +
    geom_text(aes(label = sprintf("%0.1f", round(count, digits = 1))),
              hjust=1.2, 
              vjust=0.5, 
              color="white", 
              size=3.5)+
    labs(title = "Largest TF-IDF in the book",
         subtitle = "",
         x = "Max TF-IDF",
         y = "Term",
         caption = "source: Invisible Women.pdf") + 
    theme_minimal() 
             

```  

## TF-IDF by Document

The following plot shows the 10 highest TF-IDF associated with their chapter. 
Chapter 10, *The Drugs Don't Work*, is now associated with *trial* and *drug*
To avoid redundancy, we will not comment each of the term-document. But for chapter 10, *The Drugs Don't Work*, we can see it is now associated with *trial* and *drug*. The term *tax* is still really frequent and we can now definitely state that it is specific to chapter 13, *From Purse to Wallet*. Chapter 14, *Women's Rights are Human Rights*, is in fact more specifically associated with the term *interrupt* than with the term *female* as shown in the *Term-Frequency by Document* section. 

[what's the firm term ? vr ? ]

```{r tfidf by document plot, echo=F, message=F, warning=F}

tfidf_plot <- data.tfidf2 %>% 
              tidy() %>%  
              top_n(10, count) %>% 
              ggplot(aes(x = term, 
                         y = count)) +
              geom_col(fill = "dodgerblue3", alpha = 0.5) + 
              coord_flip() + 
              facet_wrap(~ document, 
                         ncol = 2) +
              theme_minimal() +
               labs(title = "Largest TF-IDF by Document",
                    subtitle = "",
                    x = "Term",
                    y = "Count",
                    caption = "source: Invisible Women.pdf")

tfidf_plot

```                

## Keyness

The keyness measure is a chi-square test of independence indicating whether some terms are characteristic of a target compared to a reference. To illustrate that we select chapter 14, *Women’s Rights are Human Rights*, which has the vague specific term *interrupt* and compute its Keyness compare it to the other chapters (i.e. reference).

The plot below allows us to see that this chapter is characterized by the terms *party*, *politician*, *election* or even *candidate* and to conclude at first glance that this chapter is more about political topics than the rest of the corpus.

```{r keyness, echo=F, message=F, warning=F}

data.keyness <- textstat_keyness(data.dfm, 
                                 target = paste("text", 14, sep = ""))

print(textplot_keyness(data.keyness)) 
  
```

Then, we compute for each chapter of the book the keyness of terms in order to better understand what each chapter is about. The following visualization is an animated illustration (in a gif format). Each chapter is then at some point the target and the reference. 

* Chapter 1 *Can Snow-Clearing be Sexist?* displays terms related to public transportation and cities' infrastructure.
* Chapter 2 *Gender Neutral With Urinals* mentions terms in connection with public spaces and dangerous behaviors.
* Chapter 3 *The Long Friday* seem to be about parental benefits in the workplace.
* Chapter 4 *The Myth of Meritocracy* elaborates on success.
* Chapter 5 *The Henry Higgins Effect* is a bit more difficult to grasp but uses terms related to chemicals and effect on health such as cancer.
* Chapter 6 *Being Worth Less Than a Shoe* is also less specific to one vocabulary type but seems to be about profession and precariousness.
* Chapter 7 *The Plough Hypothesis* uses terms related to agriculture.
* Chapter 8 *One-Size-Fits-Men* seems to be about technologies like smartphones and data science.
* Chapter 9 *A Sea of Dudes* uses vocabulary connected to automobiles.
* Chapter 10 *The Drugs Don’t Work* is about clinical trials.
* Chapter 11 *Yentl Syndrome* uses a medical vocabulary
* Chapter 12 *A Costless Resource to Exploit* seems to be about economics.
* Chapter 13 *From Purse to Wallet* is connected to household consumption.
* Chapter 14 *Women’s Rights are Human Rights* is about politics.
* Chapter 15 *Who Will Rebuild?* implies a topic surrounding rebuilding a more peaceful world.
* Chapter 16 *It’s Not the Disaster that Kills You* evolves around extreme poverty in the world.  

```{r keyness2, echo=F, message=F, warning=F, animation.hook = "gifski", , interval = 15}

for (i in 1:nrow(data)){ 
  
   data.keyness <- textstat_keyness(data.dfm, 
                                    target = paste("text",i,sep="") )
  print(textplot_keyness(data.keyness)) 
  
}

```

## Link between words

Here, we look at how words co-occur and how inter-connected they are and to do so, we first compute the co-occurrences between terms. 

The feature co-occurrence matrix is a 5,741 by 5,741 matrix (32,959,081 elements) in which is displayed the number of times two terms co-occur in the corpus. Because of the large size of the matrix, we decide to reduce its size by keeping only co-occurrences greater than 110. The latter condition allows us to focus our attention on terms that appear the most together, implying that they have a specific connection of interest in the context of the book. After applying this condition to the matrix, we get the following smaller feature co-occurrence matrix of dimensions 20 by 20 features (400 elements). 

```{r co-occurrences, echo=F, message=F, warning=F}

# Creates a feature co-occurrence matrix


data.coocc <- fcm(data.tk2,     
                  context = "document", 
                  tri = FALSE)                 # returns upper and lower triangles of the matrix

index <- data.freq[-c(1,2),] %>% 
         filter(frequency > 110) %>%  # filter for co-occurrences greater than 110
         data.frame() %>% 
         select(feature)

data.coocc <- data.coocc[index$feature, index$feature]

data.coocc

```

Using the above feature co-occurrences matrix, we generate a network (object) displaying visually the inter-connections of interest between the co-occurring terms appearing more than 110 times in the corpus. To generate a readable network of co-occurrences, we add a second condition on the co-occurring features and we keep only the co-occurrences greater than 2,100. 

The below network reveals that the terms *datum*, *male* and *find* are central and co-occur a lot with the surrounding terms. The output shows a surprising finding which is that for a book named **Invisible Women**, the term *female* is not a central term co-occurring the most with other terms. Therefore, to dig deeper into this finding, we decide to re-introduce the term *woman* and we find an even more surprising result which is that *woman* is still not at the center of the co-occurrences despite its significantly large frequency (1,594 out of 36,160 or 4.4% of all frequencies).

```{r network, echo=F, message=F, warning=F, fig.width=10}

# Creates a feature co-occurrence matrix
# Keep strongest co-occurrences
data.coocc[data.coocc <= 2100] <- 0
data.coocc[data.coocc > 2100] <- 1

# Creates a network from the co-occurrences matrix
network <- graph_from_adjacency_matrix(data.coocc, 
                                       mode = "undirected", 
                                       diag = FALSE)

plot(network, 
     layout = layout_with_kk)
title(main = "Network graph", sub = "source: Invisible Women.pdf")
  
```

## Dispersion Plot 

After investigating term co-occurrences, we look at how terms move together in the book. Dispersion or X-Ray plots inspect where a specific token is used in each text by locating a pattern in each text. 

The below lexical dispersion plot shows how the terms *female* and *male* move along the chapters. First, *male* is found in all chapters but only once in chapter 6 *Being Worth Less Than A Shoe* whereas as *female* is only not found in chapter 15, namely *Who Will Rebuild*. When considering the implication of the title of this chapter, this finding seems a bit curious. Second, these two terms often seem to appear together at some point in chapters. Third, we also see that they are both present in chapters 4 *The Long Friday* and 14 *Women's Rights are Human Rights* at a higher frequency but not necessarily used at the same location suggesting that the author might compare the two more in these chapters.   

```{r pattern location, message=FALSE, warning=FALSE, include=FALSE}

# Checks the result
head(kwic(data.cp, pattern = c("female","male")))

kbl(head(kwic(data.cp, 
              pattern = c("female","male"))), 
    caption = "Pattern Location") %>% 
  kable_styling(bootstrap_options = c("striped", "hover"), 
                full_width = NULL)  

```

```{r xray plot, echo=F, message=F, warning=F}

# Plot
textplot_xray(kwic(data.cp, pattern = c("female","male"))) +
 labs(title = "Lexical dispersion plot: female and male",
                   subtitle = "",
                   caption ="source: Invisible Women.pdf")
```

After exploring the movements of *female* and *male*, we look at the movements between *female* and *sex*. Note that here *sex* is reduced to its lemma so it could refer to the gender, the nature of a relation or any other terms related to sexuality. The below plot shows that the term *sex* appears more in chapter 10 *The Drugs Don't Work* and that *female* and *sex* are not necessarily associated. 

```{r xray-plot 2 patterns, echo=F, message=F, warning=F}

# Plot
textplot_xray(kwic(data.cp, pattern = c("female")),
              kwic(data.cp, pattern = c("sex")),
              scale = "absolute") +
               labs(title = "Lexical dispersion plot: female and sex",
                    subtitle = "",
                    caption ="source: Invisible Women.pdf")

```

Lastly, we explore the movements of *male* and *sex*. This following plot reveals that *male* and *sex* seem to be used together most often in Chapter 10 *The Drugs Don't Work*. Furthermore, using previous results where we find that chapter 10 is associated with *trial* and *drug*, we can conclude that this chapter probably focuses on clinical trials and gender.

```{r xray plot 2 patterns, echo=F, message=F, warning=F}

# Plot
textplot_xray(kwic(data.cp, pattern = c("male")),
              kwic(data.cp, pattern = c("sex")),
              scale = "absolute") +
               labs(title = "Lexical dispersion plot: male and sex",
                    subtitle = "",
                    caption ="source: Invisible Women.pdf")

```

## Lexical Diversity

Lexical diversity is a diversity index that measures the richness of the vocabulary in one document. 

### Token-Type Ratio (TTR) 

The TTR is a diversity measure indicating a document's richness in the number of token types. The more types of tokens are found in a document, the richest is the vocabulary of this specific document. The closest to 1 the TTR is, the richest the vocabulary of a document is. We need to be careful with the TTR measure because it is dependent on the length of the document. TTR is computed using the document-term matrix.

The below graph sorts chapters of the book by descending TTR. According to TTR, chapter 15 *Who Will Rebuild?* has the richest vocabulary among all chapters of the book with a TTR of 0.592 and chapter 3 *The Long Friday* has the poorest with a TTR of 0.374. Overall, the richness of vocabulary is not very diverse which could be explained by the fact that the author focuses on the specific gender issue, therefore using repetitively gender-specific terms. 

```{r TTR plot, echo=F, message=F, warning=F, fig.width=8}

ttr <- data.dfm2 %>% 
       textstat_lexdiv()  # computes the lexical diversity

ttr <- ttr %>%
       arrange(desc(ttr$TTR))

ttr %>% 
  ggplot(aes(reorder(document, -TTR), TTR)) + 
  geom_bar(stat = "identity", 
           fill = "dodgerblue3", 
           alpha = 0.5) +
  geom_text(aes(label = sprintf("%0.3f", round(TTR, digits = 3))),
                              vjust=1.6, color="white", size=3.5)+
  labs(title = "Token-Type Ration (TTR)",
       subtitle = "Chapter 15 has the richest vocabulary",
       x = "Chapter",
       y = "TTR",
       caption ="source: Invisible Women.pdf") +
       theme_minimal()

```

### Moving-Average Token-Type Ratio (MATTR)

The Moving-Average Token-Type Ratio is an average of the Token-Type Ratio. It is an algorithm using windows of the text to compute the TTR and repeating several times over different windows of the same size the TTR computation. The advantage of the MATTR is that it is less dependent on the length of the document than the TTR. Note that a too large window can produce an error since no local TTR can be computed and a too small window results in pointless values (always 1). MATTR is computed using ordered tokens. 

Considering the documents lenght, we decide to compute the MATTR with a window of 80 tokens. The below graph shows that the Moving-Average Token-Type Ratio among chapters are very similar and that it ranges from 0.725 to 0.798. According to the MATTR, chapter 15 *Who Will Rebuild?* still has the richest vocabulary with an MATTR of 0.798. 

```{r MATTR plot, echo=F, message=F, warning=F, fig.width=8}

mattr <- data.tk2 %>% 
         textstat_lexdiv(measure = "MATTR", 
                         MATTR_window = 80)    
mattr <- mattr %>%
         arrange(desc(mattr$MATTR))

mattr %>% 
 ggplot(aes(reorder(document, -MATTR), MATTR)) + 
 geom_bar(stat = "identity", 
          fill = "dodgerblue3", 
          alpha = 0.5) +
 geom_text(aes(label = sprintf("%0.3f", round(MATTR, digits = 3))),
           vjust = 1.6, 
           color = "white", 
           size = 3.5)+
 labs(title = "Moving-Average Token-Type Ratio (MATTR)",
      subtitle = "",
      x = "Chapter",
      y = "MATTR",
      caption ="source: Invisible Women.pdf")

```


