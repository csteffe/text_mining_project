# Data

```{r, echo = FALSE, message = FALSE}
source(here::here("scripts/setup.R"))
```


Reading the data.  

```{r}
text<-pdf_text(here::here("data/Invisible Women.pdf"))
```

to create corpus with chapter : https://cran.r-project.org/web/packages/corpus/vignettes/corpus.html, and cleaning.  


```{r}
# the text starts after the Project Gutenberg header...
start <- grep("CHAPTER 1", text)
#print(text[36])

start<-start[1]

# ...end ends at the Project Gutenberg footer.
stop <- grep("Afterword", text) - 1
#print(text[259])
stop<-stop[2]

lines <- text[start:stop]
```




```{r}


# chapters start with "1.", "2.", etc...
chapter <- grep("CHAPTER", lines)


# get the section texts (including the front matter)
start <- c(1, chapter) # + 1 to skip title
end <- c(chapter - 1, length(lines))
text <- mapply(function(s, e) paste(lines[s:e], collapse = "\n"), start, end)

# trim leading and trailing white space
text <- trimws(text)

# discard the front matter
text <- text[-1]

```


## Tokenization

```{r}
## Libraries needed for the application
library(readr)
library(quanteda)
library(quanteda.textplots)
library(quanteda.textstats)
library(tidytext)
library(dplyr)
library(ggplot2)
library(broom)

data.cp <- corpus(text)


summary(data.cp)

data.tk <- tokens(data.cp,
                 removeNumbers=TRUE,
                 remove_punct=TRUE,
                 remove_symbols=TRUE,
                 remove_separators=TRUE)

data.tk <- data.tk %>% tokens_tolower() %>% tokens_remove(stop_words$word)

## Compute the DTM, TF-IDF and global frequencies
data.dfm <- dfm(data.tk)
data.tfidf <- dfm_tfidf(data.dfm)  
data.freq <- textstat_frequency(data.dfm)
```

```{r}
### Plot the 20 most frequent terms
data.freq %>% top_n(20, frequency) %>%
  ggplot(aes(x=reorder(feature, frequency), y=frequency)) + geom_bar(stat = "identity") + coord_flip() +
  xlab("Frequency") + ylab("term")
```



